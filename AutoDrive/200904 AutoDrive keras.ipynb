{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"200904 AutoDrive keras.ipynb","provenance":[{"file_id":"1gKq-0MLlJeHvc3xr5X59nLXaPhQMgv7W","timestamp":1599218089534},{"file_id":"1bLAzMS2QIjOU66Xa0FWg9kOPpblPB6v-","timestamp":1598994503083},{"file_id":"1DbzoeLviHZqgsEfh7gXsJmu8xCAA8XKY","timestamp":1597363248029},{"file_id":"1UNshqAjzCVPOTGOL8cgSH_eESwx2uiLA","timestamp":1596806015753},{"file_id":"1SkoA3wQ_3cYtxt3P5pF-DSB-MFGGRQnN","timestamp":1596568903906}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6AaZtlvVZ-2T","colab_type":"text"},"source":["## **Setup**"]},{"cell_type":"code","metadata":{"id":"Y9zRahJVgJ4a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1599277518277,"user_tz":240,"elapsed":960,"user":{"displayName":"Ben Isaacoff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3nUiOdsgkozK1xAE5MY_jUwIPqARauxrhKcoSXg=s64","userId":"05140603897186853519"}},"outputId":"af348572-1478-4c36-b14b-56b7aa338c0d"},"source":["from google.colab import drive\n","mount_path = '/content/gdrive/'\n","drive.mount(mount_path)\n","\n","model_path='My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kSMa29SfVfPy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1599277518282,"user_tz":240,"elapsed":948,"user":{"displayName":"Ben Isaacoff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3nUiOdsgkozK1xAE5MY_jUwIPqARauxrhKcoSXg=s64","userId":"05140603897186853519"}},"outputId":"f71bc816-a6a2-434d-aca1-292d43746216"},"source":["import os\n","import pickle\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import datetime\n","import pytz\n","from zipfile import ZipFile\n","from tempfile import TemporaryDirectory\n","import requests\n","import cv2\n","import shutil\n","import glob\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","\n","# from sklearn.metrics import roc_auc_score, roc_curve, auc\n","# from sklearn.model_selection import train_test_split\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","from google.colab.patches import cv2_imshow \n","\n","# plot options\n","# plt.rcParams.update({'font.size': 11})\n","plt.style.use('fivethirtyeight')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fTFXzZifp9sb","colab_type":"text"},"source":["# Data Loading"]},{"cell_type":"code","metadata":{"id":"Un9nDQwOp_pq","colab_type":"code","colab":{}},"source":["# custom copytree because Colab doesn't have the latest version of shutil.copytree which now contains the dirs_exist_ok flag solving this issue\n","# copied verbatim from https://stackoverflow.com/a/12514470/5991868\n","def copytree(src, dst, symlinks=False, ignore=None):\n","    for item in os.listdir(src):\n","        s = os.path.join(src, item)\n","        d = os.path.join(dst, item)\n","        if os.path.isdir(s):\n","            shutil.copytree(s, d, symlinks, ignore)\n","        else:\n","            shutil.copy2(s, d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7cl9qzei_51","colab_type":"code","colab":{}},"source":["# home_dir is the home directory for the images, from which training and validation splits will be taken\n","home_dir='/content/All_Data/'\n","\n","# this can take a bit (maybe 30s)\n","if not os.path.exists(home_dir):\n","  os.mkdir(home_dir)\n","  for cview in ['Front','Left','Rear','Right']:\n","    os.mkdir(os.path.join(home_dir,'camera'+cview))\n","\n","  urlbase = 'https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/autodri/v0.1/'\n","\n","  for filename in ['train','val']:\n","    # create a temporary directory using TemporaryDirectory and context manager and unzip to there\n","    with TemporaryDirectory() as tmpdirname:\n","      # download the file\n","      requrl = requests.get(f'{urlbase}{filename}.zip')\n","      with open(f'{tmpdirname}/{filename}.zip', \"wb\") as zip:\n","        zip.write(requrl.content)\n","      # unzip\n","      with ZipFile(f'{tmpdirname}/{filename}.zip','r') as zip_ref:\n","        zip_ref.extractall(tmpdirname)\n","      # copy the data to the All_Data dir\n","      shutil.copy2(f'{tmpdirname}/{filename}/{filename}.csv',f'{home_dir}/{filename}.csv')\n","      for cview in ['Front','Left','Rear','Right']:\n","        copytree(f'{tmpdirname}/{filename}/camera{cview}/',f'{home_dir}/camera{cview}/')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FyzTtC0Yz9tM","colab_type":"code","colab":{}},"source":["combdf=pd.read_csv(f'{home_dir}/train.csv').append(\n","    pd.read_csv(f'{home_dir}/val.csv'),ignore_index=True)\n","\n","# creat the img_list column\n","combdf['img_list']=combdf['filename'].apply(\n","    lambda fname: [os.path.join(home_dir,f'camera{cview}/{fname}') for cview in ['Left','Front','Right','Rear']])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2phEqqvBWlyF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"status":"ok","timestamp":1599277518881,"user_tz":240,"elapsed":1502,"user":{"displayName":"Ben Isaacoff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3nUiOdsgkozK1xAE5MY_jUwIPqARauxrhKcoSXg=s64","userId":"05140603897186853519"}},"outputId":"6b822d89-5e3d-40d0-f016-ae0b5c938476"},"source":["combdf.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>canSteering</th>\n","      <th>img_list</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>33856.jpg</td>\n","      <td>180.000000</td>\n","      <td>[/content/All_Data/cameraLeft/33856.jpg, /cont...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>61909.jpg</td>\n","      <td>-194.370014</td>\n","      <td>[/content/All_Data/cameraLeft/61909.jpg, /cont...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36269.jpg</td>\n","      <td>-39.000471</td>\n","      <td>[/content/All_Data/cameraLeft/36269.jpg, /cont...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>60259.jpg</td>\n","      <td>-185.300714</td>\n","      <td>[/content/All_Data/cameraLeft/60259.jpg, /cont...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50681.jpg</td>\n","      <td>44.939983</td>\n","      <td>[/content/All_Data/cameraLeft/50681.jpg, /cont...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    filename  canSteering                                           img_list\n","0  33856.jpg   180.000000  [/content/All_Data/cameraLeft/33856.jpg, /cont...\n","1  61909.jpg  -194.370014  [/content/All_Data/cameraLeft/61909.jpg, /cont...\n","2  36269.jpg   -39.000471  [/content/All_Data/cameraLeft/36269.jpg, /cont...\n","3  60259.jpg  -185.300714  [/content/All_Data/cameraLeft/60259.jpg, /cont...\n","4  50681.jpg    44.939983  [/content/All_Data/cameraLeft/50681.jpg, /cont..."]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"7adaRTrtz-Tw","colab_type":"code","colab":{}},"source":["def trainvaldfs(combdf, num_folds, val_pct, truly_random):\n","  '''\n","  returns a dictionary[fold_num][train or val] : dataframe\n","  eg cvdict[0]['train']\n","  '''\n","  cvdict={key:{'train':None,'val':None} for key in range(num_folds)}\n","\n","  assert(val_pct<=(1/num_folds))\n","\n","  if truly_random:\n","    rng = np.random.RandomState() # random seeding\n","  else:\n","    rng = np.random.RandomState(42) # deterministic seeding\n","  \n","  inds=combdf.index.to_list()\n","  # shuffle the image array. NOTE all the randomness in the train-val split comes from this shuffle\n","  rng.shuffle(inds)\n","\n","  # size of the fold\n","  foldsz=np.floor(len(inds)/num_folds).astype(int)\n","  # how many validation items\n","  numval=np.floor(val_pct*len(inds)).astype(int)\n","\n","  for cvfold in range(num_folds):\n","    valinds=inds[(cvfold*foldsz):(cvfold*foldsz+numval)]\n","    cvdict[cvfold]['val']=combdf.loc[valinds]\n","    cvdict[cvfold]['train']=combdf.loc[np.setdiff1d(inds,valinds)]\n","\n","  return cvdict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4h7TVuZP1fyU","colab_type":"code","colab":{}},"source":["cvdict=trainvaldfs(combdf,3,0.15,False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXCSd0WnopsV","colab_type":"code","colab":{}},"source":["# ind=np.random.choice(cvdict[0]['train'].index)\n","# for img in cvdict[0]['train'].loc[ind,'img_list']:\n","#   cv2_imshow(cv2.imread(img))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzerJeIB9Ay2","colab_type":"code","colab":{}},"source":["def plot_training_history(history):\n","  # keras appends a number after some of the keys, this little ditty here just pulls them out\n","  histkeys=pd.Series(list(history.history.keys()))\n","  histkeys=histkeys[histkeys.str.contains('mse')]\n","  val_key=histkeys[histkeys.str.contains('val')].values[0]\n","  auc_key=histkeys[~histkeys.str.contains('val')].values[0]\n","\n","  plt.figure(figsize=(10, 5))\n","  # summarize history for auc\n","  plt.subplot(1,2,1)\n","  plt.plot(history.history[auc_key])\n","  plt.plot(history.history[val_key])\n","  plt.title('Training MSE')\n","  plt.ylabel('MSE')\n","  plt.xlabel('Epoch')\n","  plt.legend(['train', 'test'], loc='upper left')\n","  plt.grid(True)\n","  plt.tight_layout()\n","  \n","  # summarize history for loss\n","  plt.subplot(1,2,2)\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Training Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['train', 'test'], loc='upper left')\n","  plt.grid(True)\n","  plt.tight_layout()\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CsL6yeBuMRGa","colab_type":"text"},"source":["# Model Setup"]},{"cell_type":"code","metadata":{"id":"ozAPC4LxNxXS","colab_type":"code","colab":{}},"source":["base_model = keras.applications.DenseNet201(include_top = False, weights = 'imagenet',\n","    input_shape = (224, 224, 3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2f2lY2UMQyj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1599277535539,"user_tz":240,"elapsed":18076,"user":{"displayName":"Ben Isaacoff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3nUiOdsgkozK1xAE5MY_jUwIPqARauxrhKcoSXg=s64","userId":"05140603897186853519"}},"outputId":"6a2e51e4-a25c-42b2-ec8e-04fdf0a69623"},"source":["# create a Sequential model\n","model = keras.models.Sequential()\n","\n","# add base_model for 4 input images (keeping the right shape\n","model.add(keras.layers.TimeDistributed(base_model, input_shape=(4, 224, 224, 3)))\n","\n","# now, flatten on each output to send 4 outputs with one dimension to LSTM\n","model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n","model.add(keras.layers.LSTM(256, activation='relu', return_sequences=False))\n","\n","# finalize with standard MLP\n","model.add(keras.layers.Dense(128, activation=None))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Activation('relu'))\n","model.add(keras.layers.Dropout(0.25))\n","\n","model.add(keras.layers.Dense(64, activation=None))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Activation('relu'))\n","model.add(keras.layers.Dropout(0.25))\n","\n","model.add(keras.layers.Dense(1,activation='linear'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VoQFfJrrmx0A","colab_type":"code","colab":{}},"source":["# freeze the base model which is inside the first timedistributed layer\n","model.layers[0].trainable=False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cqRMbFqtPvrB","colab_type":"text"},"source":["### Compile model"]},{"cell_type":"code","metadata":{"id":"3Llhog37MQwD","colab_type":"code","colab":{}},"source":["init_lr=1e-2\n","optimizer = keras.optimizers.Nadam(lr=init_lr)\n","loss_function = keras.losses.MeanSquaredError()\n","\n","model.compile(loss=loss_function, optimizer=optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d-3wjV6j_S4b","colab_type":"code","colab":{}},"source":["def get_imgs(imlist):\n","  imgs=[]\n","  for impath in imlist:\n","    img = load_img(impath,target_size=(224, 224))\n","    imgs.append(img_to_array(img))\n","    # Pillow images should be closed after `load_img`,\n","    # but not PIL images.\n","    if hasattr(img, 'close'):\n","      img.close()\n","                \n","  return np.stack(imgs,axis=0)\n","\n","def imageseq_generator(df, batch_size = 64):  \n","  inds=df.index.to_list()\n","  while True:\n","    # shuffle the indices for the epoch\n","    np.random.shuffle(inds)\n","\n","    # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size &lt;= num_samples]\n","    for offset in range(0, len(inds), batch_size):\n","      # Get the samples you'll use in this batch\n","      batch_inds = inds[offset:(offset+batch_size)]\n","\n","      batch_input  = []\n","      batch_output = []     \n","      # Read in each input, perform preprocessing and get labels\n","      for ind in batch_inds:\n","        batch_input.append(get_imgs(df.loc[ind,'img_list']))\n","        batch_output.append(df.loc[ind,'canSteering'])\n","\n","      # Return a tuple of (input, output) to feed the network    \n","      yield (np.array(batch_input), np.array(batch_output))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wo1Urmrn46si","colab_type":"code","colab":{}},"source":["# # set up Tensorboard\n","# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","# %tensorboard --logdir logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnhxun05MQtp","colab_type":"code","colab":{}},"source":["# early stopping callback\n","# patience is number of epochs without improvement\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience= 4, min_delta = 100, restore_best_weights = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWweCO_7opeg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":759},"executionInfo":{"status":"ok","timestamp":1599283752891,"user_tz":240,"elapsed":6235363,"user":{"displayName":"Ben Isaacoff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3nUiOdsgkozK1xAE5MY_jUwIPqARauxrhKcoSXg=s64","userId":"05140603897186853519"}},"outputId":"25e42585-cc0d-41ff-f411-47c8ea50fe13"},"source":["# # tensorboard \n","# logdir = os.path.join(\"logs\", datetime.datetime.now(pytz.timezone('US/Eastern')).strftime(\"%y%m%d_%H%M\"))\n","# tb_cb = keras.callbacks.TensorBoard(logdir)\n","\n","cv_fold=1\n","\n","datestr=datetime.datetime.now(pytz.timezone('US/Eastern')).strftime(\"%y%m%d_%H%M\")\n","checkpoint_filepath=f'{os.path.join(mount_path,model_path)}{datestr}_DenseNet_cv{cv_fold}_AutoDrive_frozen'\n","model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath = checkpoint_filepath,\n","    save_weights_only = False,\n","    monitor = 'val_loss',\n","    mode = 'min',\n","    save_best_only = True,\n","    verbose = 1)\n","\n","train_df=cvdict[cv_fold]['train']\n","val_df=cvdict[cv_fold]['val']\n","\n","batch_size = 64\n","max_epochs=25\n","\n","train_steps=train_df.shape[0]//batch_size\n","val_steps=val_df.shape[0]//batch_size\n","\n","# train it!\n","history = model.fit(imageseq_generator(train_df,batch_size), epochs = max_epochs,\n","                    validation_data = imageseq_generator(val_df,batch_size),\n","                    steps_per_epoch = train_steps, validation_steps = val_steps,\n","                    callbacks = [early_stopping_cb, model_checkpoint_cb])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n","832/832 [==============================] - ETA: 0s - loss: 17410.5996\n","Epoch 00001: val_loss improved from inf to 15708.64355, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200904_2345_DenseNet_cv1_AutoDrive_frozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200904_2345_DenseNet_cv1_AutoDrive_frozen/assets\n","832/832 [==============================] - 740s 890ms/step - loss: 17410.5996 - val_loss: 15708.6436\n","Epoch 2/25\n","832/832 [==============================] - ETA: 0s - loss: 7943.4688\n","Epoch 00002: val_loss improved from 15708.64355 to 9000.51660, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200904_2345_DenseNet_cv1_AutoDrive_frozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200904_2345_DenseNet_cv1_AutoDrive_frozen/assets\n","832/832 [==============================] - 751s 902ms/step - loss: 7943.4688 - val_loss: 9000.5166\n","Epoch 3/25\n","832/832 [==============================] - ETA: 0s - loss: 5884.7329\n","Epoch 00003: val_loss improved from 9000.51660 to 6234.36279, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200904_2345_DenseNet_cv1_AutoDrive_frozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200904_2345_DenseNet_cv1_AutoDrive_frozen/assets\n","832/832 [==============================] - 736s 885ms/step - loss: 5884.7329 - val_loss: 6234.3628\n","Epoch 4/25\n","832/832 [==============================] - ETA: 0s - loss: 5049.8516\n","Epoch 00004: val_loss improved from 6234.36279 to 5775.46631, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200904_2345_DenseNet_cv1_AutoDrive_frozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200904_2345_DenseNet_cv1_AutoDrive_frozen/assets\n","832/832 [==============================] - 747s 898ms/step - loss: 5049.8516 - val_loss: 5775.4663\n","Epoch 5/25\n","832/832 [==============================] - ETA: 0s - loss: 4570.0498\n","Epoch 00005: val_loss improved from 5775.46631 to 4619.68799, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200904_2345_DenseNet_cv1_AutoDrive_frozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200904_2345_DenseNet_cv1_AutoDrive_frozen/assets\n","832/832 [==============================] - 755s 908ms/step - loss: 4570.0498 - val_loss: 4619.6880\n","Epoch 6/25\n","832/832 [==============================] - ETA: 0s - loss: 4221.4229\n","Epoch 00006: val_loss did not improve from 4619.68799\n","832/832 [==============================] - 632s 759ms/step - loss: 4221.4229 - val_loss: 5412.2100\n","Epoch 7/25\n","832/832 [==============================] - ETA: 0s - loss: 4007.5027\n","Epoch 00007: val_loss did not improve from 4619.68799\n","832/832 [==============================] - 611s 734ms/step - loss: 4007.5027 - val_loss: 6593.9946\n","Epoch 8/25\n","832/832 [==============================] - ETA: 0s - loss: 3762.0217\n","Epoch 00008: val_loss did not improve from 4619.68799\n","832/832 [==============================] - 612s 736ms/step - loss: 3762.0217 - val_loss: 5085.5864\n","Epoch 9/25\n","832/832 [==============================] - ETA: 0s - loss: 3505.2891\n","Epoch 00009: val_loss did not improve from 4619.68799\n","832/832 [==============================] - 615s 739ms/step - loss: 3505.2891 - val_loss: 15058.1572\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eog8kD-IoG6G","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}