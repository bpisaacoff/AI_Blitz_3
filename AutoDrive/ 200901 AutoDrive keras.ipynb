{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":" 200901 AutoDrive keras.ipynb","provenance":[{"file_id":"1bLAzMS2QIjOU66Xa0FWg9kOPpblPB6v-","timestamp":1598994503083},{"file_id":"1DbzoeLviHZqgsEfh7gXsJmu8xCAA8XKY","timestamp":1597363248029},{"file_id":"1UNshqAjzCVPOTGOL8cgSH_eESwx2uiLA","timestamp":1596806015753},{"file_id":"1SkoA3wQ_3cYtxt3P5pF-DSB-MFGGRQnN","timestamp":1596568903906}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6AaZtlvVZ-2T","colab_type":"text"},"source":["## **Setup**"]},{"cell_type":"code","metadata":{"id":"Y9zRahJVgJ4a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"executionInfo":{"status":"ok","timestamp":1599215037562,"user_tz":240,"elapsed":25185,"user":{"displayName":"Ben Isaacoff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3nUiOdsgkozK1xAE5MY_jUwIPqARauxrhKcoSXg=s64","userId":"05140603897186853519"}},"outputId":"c39d03f4-abc7-4849-e5ed-fb5445fe9cc4"},"source":["from google.colab import drive\n","mount_path = '/content/gdrive/'\n","drive.mount(mount_path)\n","\n","model_path='My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kSMa29SfVfPy","colab_type":"code","colab":{}},"source":["import os\n","import pickle\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import datetime\n","import pytz\n","from zipfile import ZipFile\n","from tempfile import TemporaryDirectory\n","import requests\n","import cv2\n","import shutil\n","import glob\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","\n","# from sklearn.metrics import roc_auc_score, roc_curve, auc\n","# from sklearn.model_selection import train_test_split\n","\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","from google.colab.patches import cv2_imshow \n","\n","# plot options\n","# plt.rcParams.update({'font.size': 11})\n","plt.style.use('fivethirtyeight')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fTFXzZifp9sb","colab_type":"text"},"source":["# Data Loading"]},{"cell_type":"code","metadata":{"id":"Un9nDQwOp_pq","colab_type":"code","colab":{}},"source":["# custom copytree because Colab doesn't have the latest version of shutil.copytree which now contains the dirs_exist_ok flag solving this issue\n","# copied verbatim from https://stackoverflow.com/a/12514470/5991868\n","def copytree(src, dst, symlinks=False, ignore=None):\n","    for item in os.listdir(src):\n","        s = os.path.join(src, item)\n","        d = os.path.join(dst, item)\n","        if os.path.isdir(s):\n","            shutil.copytree(s, d, symlinks, ignore)\n","        else:\n","            shutil.copy2(s, d)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A7cl9qzei_51","colab_type":"code","colab":{}},"source":["# home_dir is the home directory for the images, from which training and validation splits will be taken\n","home_dir='/content/All_Data/'\n","\n","# this can take a bit (maybe 30s)\n","if not os.path.exists(home_dir):\n","  os.mkdir(home_dir)\n","  for cview in ['Front','Left','Rear','Right']:\n","    os.mkdir(os.path.join(home_dir,'camera'+cview))\n","\n","  urlbase = 'https://datasets.aicrowd.com/default/aicrowd-practice-challenges/public/autodri/v0.1/'\n","\n","  for filename in ['train','val']:\n","    # create a temporary directory using TemporaryDirectory and context manager and unzip to there\n","    with TemporaryDirectory() as tmpdirname:\n","      # download the file\n","      requrl = requests.get(f'{urlbase}{filename}.zip')\n","      with open(f'{tmpdirname}/{filename}.zip', \"wb\") as zip:\n","        zip.write(requrl.content)\n","      # unzip\n","      with ZipFile(f'{tmpdirname}/{filename}.zip','r') as zip_ref:\n","        zip_ref.extractall(tmpdirname)\n","      # copy the data to the All_Data dir\n","      shutil.copy2(f'{tmpdirname}/{filename}/{filename}.csv',f'{home_dir}/{filename}.csv')\n","      for cview in ['Front','Left','Rear','Right']:\n","        copytree(f'{tmpdirname}/{filename}/camera{cview}/',f'{home_dir}/camera{cview}/')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FyzTtC0Yz9tM","colab_type":"code","colab":{}},"source":["combdf=pd.read_csv(f'{home_dir}/train.csv').append(\n","    pd.read_csv(f'{home_dir}/val.csv'),ignore_index=True)\n","\n","# creat the img_list column\n","combdf['img_list']=combdf['filename'].apply(\n","    lambda fname: [os.path.join(home_dir,f'camera{cview}/{fname}') for cview in ['Left','Front','Right','Rear']])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2phEqqvBWlyF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"status":"ok","timestamp":1599177523819,"user_tz":240,"elapsed":409678,"user":{"displayName":"Ben Isaacoff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3nUiOdsgkozK1xAE5MY_jUwIPqARauxrhKcoSXg=s64","userId":"05140603897186853519"}},"outputId":"6adb2ea7-f8cb-4d1f-be3c-a798e3f96c28"},"source":["combdf.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>filename</th>\n","      <th>canSteering</th>\n","      <th>img_list</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>33856.jpg</td>\n","      <td>180.000000</td>\n","      <td>[/content/All_Data/cameraLeft/33856.jpg, /cont...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>61909.jpg</td>\n","      <td>-194.370014</td>\n","      <td>[/content/All_Data/cameraLeft/61909.jpg, /cont...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36269.jpg</td>\n","      <td>-39.000471</td>\n","      <td>[/content/All_Data/cameraLeft/36269.jpg, /cont...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>60259.jpg</td>\n","      <td>-185.300714</td>\n","      <td>[/content/All_Data/cameraLeft/60259.jpg, /cont...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50681.jpg</td>\n","      <td>44.939983</td>\n","      <td>[/content/All_Data/cameraLeft/50681.jpg, /cont...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    filename  canSteering                                           img_list\n","0  33856.jpg   180.000000  [/content/All_Data/cameraLeft/33856.jpg, /cont...\n","1  61909.jpg  -194.370014  [/content/All_Data/cameraLeft/61909.jpg, /cont...\n","2  36269.jpg   -39.000471  [/content/All_Data/cameraLeft/36269.jpg, /cont...\n","3  60259.jpg  -185.300714  [/content/All_Data/cameraLeft/60259.jpg, /cont...\n","4  50681.jpg    44.939983  [/content/All_Data/cameraLeft/50681.jpg, /cont..."]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"7adaRTrtz-Tw","colab_type":"code","colab":{}},"source":["def trainvaldfs(combdf, num_folds, val_pct, truly_random):\n","  '''\n","  returns a dictionary[fold_num][train or val] : dataframe\n","  eg cvdict[0]['train']\n","  '''\n","  cvdict={key:{'train':None,'val':None} for key in range(num_folds)}\n","\n","  assert(val_pct<=(1/num_folds))\n","\n","  if truly_random:\n","    rng = np.random.RandomState() # random seeding\n","  else:\n","    rng = np.random.RandomState(42) # deterministic seeding\n","  \n","  inds=combdf.index.to_list()\n","  # shuffle the image array. NOTE all the randomness in the train-val split comes from this shuffle\n","  rng.shuffle(inds)\n","\n","  # size of the fold\n","  foldsz=np.floor(len(inds)/num_folds).astype(int)\n","  # how many validation items\n","  numval=np.floor(val_pct*len(inds)).astype(int)\n","\n","  for cvfold in range(num_folds):\n","    valinds=inds[(cvfold*foldsz):(cvfold*foldsz+numval)]\n","    cvdict[cvfold]['val']=combdf.loc[valinds]\n","    cvdict[cvfold]['train']=combdf.loc[np.setdiff1d(inds,valinds)]\n","\n","  return cvdict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cOqJrgKXViFq","colab_type":"code","colab":{}},"source":["cvdict=trainvaldfs(combdf,3,0.15,False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QXCSd0WnopsV","colab_type":"code","colab":{}},"source":["# ind=np.random.choice(cvdict[0]['train'].index)\n","# for img in cvdict[0]['train'].loc[ind,'img_list']:\n","#   cv2_imshow(cv2.imread(img))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzerJeIB9Ay2","colab_type":"code","colab":{}},"source":["def plot_training_history(history):\n","  # keras appends a number after some of the keys, this little ditty here just pulls them out\n","  histkeys=pd.Series(list(history.history.keys()))\n","  histkeys=histkeys[histkeys.str.contains('mse')]\n","  val_key=histkeys[histkeys.str.contains('val')].values[0]\n","  auc_key=histkeys[~histkeys.str.contains('val')].values[0]\n","\n","  plt.figure(figsize=(10, 5))\n","  # summarize history for auc\n","  plt.subplot(1,2,1)\n","  plt.plot(history.history[auc_key])\n","  plt.plot(history.history[val_key])\n","  plt.title('Training MSE')\n","  plt.ylabel('MSE')\n","  plt.xlabel('Epoch')\n","  plt.legend(['train', 'test'], loc='upper left')\n","  plt.grid(True)\n","  plt.tight_layout()\n","  \n","  # summarize history for loss\n","  plt.subplot(1,2,2)\n","  plt.plot(history.history['loss'])\n","  plt.plot(history.history['val_loss'])\n","  plt.title('Training Loss')\n","  plt.ylabel('Loss')\n","  plt.xlabel('Epoch')\n","  plt.legend(['train', 'test'], loc='upper left')\n","  plt.grid(True)\n","  plt.tight_layout()\n","\n","  plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CsL6yeBuMRGa","colab_type":"text"},"source":["# Model Setup"]},{"cell_type":"code","metadata":{"id":"ozAPC4LxNxXS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1599177538100,"user_tz":240,"elapsed":415199,"user":{"displayName":"Ben Isaacoff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3nUiOdsgkozK1xAE5MY_jUwIPqARauxrhKcoSXg=s64","userId":"05140603897186853519"}},"outputId":"3726c847-2434-4318-cd39-a092ee40acaa"},"source":["base_model = keras.applications.EfficientNetB4(include_top = False, weights = 'imagenet',\n","    input_shape = (224, 224, 3))\n","\n","# freeze the weights of the pre-trained layers\n","for layer in base_model.layers:\n","  layer.trainable = False"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n","71688192/71686520 [==============================] - 1s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g2f2lY2UMQyj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"executionInfo":{"status":"ok","timestamp":1599177543163,"user_tz":240,"elapsed":419181,"user":{"displayName":"Ben Isaacoff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3nUiOdsgkozK1xAE5MY_jUwIPqARauxrhKcoSXg=s64","userId":"05140603897186853519"}},"outputId":"b9b830eb-fbb9-4483-960c-916db277a043"},"source":["# create a Sequential model\n","model = keras.models.Sequential()\n","\n","# add base_model for 4 input images (keeping the right shape\n","model.add(keras.layers.TimeDistributed(base_model, input_shape=(4, 224, 224, 3)))\n","\n","# now, flatten on each output to send 4 outputs with one dimension to LSTM\n","model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n","model.add(keras.layers.LSTM(256, activation='relu', return_sequences=False))\n","\n","# finalize with standard MLP\n","model.add(keras.layers.Dense(128, activation=None))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Activation('relu'))\n","model.add(keras.layers.Dropout(0.25))\n","\n","model.add(keras.layers.Dense(64, activation=None))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Activation('relu'))\n","model.add(keras.layers.Dropout(0.25))\n","\n","model.add(keras.layers.Dense(1,activation='linear'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VoQFfJrrmx0A","colab_type":"code","colab":{}},"source":["# freeze the base model which is inside the first timedistributed layer\n","model.layers[0].trainable=False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cqRMbFqtPvrB","colab_type":"text"},"source":["### Compile model"]},{"cell_type":"code","metadata":{"id":"3Llhog37MQwD","colab_type":"code","colab":{}},"source":["init_lr=1e-2\n","optimizer = keras.optimizers.Nadam(lr=init_lr)\n","loss_function = keras.losses.MeanSquaredError()\n","\n","model.compile(loss=loss_function, optimizer=optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bnhxun05MQtp","colab_type":"code","colab":{}},"source":["# early stopping callback\n","# patience is number of epochs without improvement\n","early_stopping_cb = keras.callbacks.EarlyStopping(patience= 3, min_delta = 100, restore_best_weights = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d-3wjV6j_S4b","colab_type":"code","colab":{}},"source":["def get_imgs(imlist):\n","  imgs=[]\n","  for impath in imlist:\n","    img = load_img(impath,target_size=(224, 224))\n","    imgs.append(img_to_array(img))\n","    # Pillow images should be closed after `load_img`,\n","    # but not PIL images.\n","    if hasattr(img, 'close'):\n","      img.close()\n","                \n","  return np.stack(imgs,axis=0)\n","\n","def imageseq_generator(df, batch_size = 64):  \n","  inds=df.index.to_list()\n","  while True:\n","    # shuffle the indices for the epoch\n","    np.random.shuffle(inds)\n","\n","    # Get index to start each batch: [0, batch_size, 2*batch_size, ..., max multiple of batch_size &lt;= num_samples]\n","    for offset in range(0, len(inds), batch_size):\n","      # Get the samples you'll use in this batch\n","      batch_inds = inds[offset:(offset+batch_size)]\n","\n","      batch_input  = []\n","      batch_output = []     \n","      # Read in each input, perform preprocessing and get labels\n","      for ind in batch_inds:\n","        batch_input.append(get_imgs(df.loc[ind,'img_list']))\n","        batch_output.append(df.loc[ind,'canSteering'])\n","\n","      # Return a tuple of (input, output) to feed the network    \n","      yield (np.array(batch_input), np.array(batch_output))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wo1Urmrn46si","colab_type":"code","colab":{}},"source":["# # set up Tensorboard\n","# logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","# %tensorboard --logdir logs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWweCO_7opeg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1599186407114,"user_tz":240,"elapsed":8862911,"user":{"displayName":"Ben Isaacoff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3nUiOdsgkozK1xAE5MY_jUwIPqARauxrhKcoSXg=s64","userId":"05140603897186853519"}},"outputId":"adabde84-c8d2-40a2-90f1-12542e47b3e9"},"source":["# # tensorboard \n","# logdir = os.path.join(\"logs\", datetime.datetime.now(pytz.timezone('US/Eastern')).strftime(\"%y%m%d_%H%M\"))\n","# tb_cb = keras.callbacks.TensorBoard(logdir)\n","\n","datestr=datetime.datetime.now(pytz.timezone('US/Eastern')).strftime(\"%y%m%d_%H%M\")\n","checkpoint_filepath=f'{os.path.join(mount_path,model_path)}{datestr}_AutoDrive_frozen'\n","model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath = checkpoint_filepath,\n","    save_weights_only = False,\n","    monitor = 'val_loss',\n","    mode = 'min',\n","    save_best_only = True,\n","    verbose = 1)\n","\n","cv_fold=0\n","\n","train_df=cvdict[cv_fold]['train']\n","val_df=cvdict[cv_fold]['val']\n","\n","batch_size = 64\n","max_epochs=20\n","\n","train_steps=train_df.shape[0]//batch_size\n","val_steps=val_df.shape[0]//batch_size\n","\n","# train it!\n","history = model.fit(imageseq_generator(train_df,batch_size), epochs = max_epochs,\n","                    validation_data = imageseq_generator(val_df,batch_size),\n","                    steps_per_epoch = train_steps, validation_steps = val_steps,\n","                    callbacks = [early_stopping_cb, model_checkpoint_cb])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","832/832 [==============================] - ETA: 0s - loss: 18153.4805\n","Epoch 00001: val_loss improved from inf to 10865.78125, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen/assets\n","832/832 [==============================] - 754s 907ms/step - loss: 18153.4805 - val_loss: 10865.7812\n","Epoch 2/20\n","832/832 [==============================] - ETA: 0s - loss: 9291.2139\n","Epoch 00002: val_loss improved from 10865.78125 to 8203.83691, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen/assets\n","832/832 [==============================] - 763s 917ms/step - loss: 9291.2139 - val_loss: 8203.8369\n","Epoch 3/20\n","832/832 [==============================] - ETA: 0s - loss: 7590.7153\n","Epoch 00003: val_loss did not improve from 8203.83691\n","832/832 [==============================] - 636s 765ms/step - loss: 7590.7153 - val_loss: 11650.9170\n","Epoch 4/20\n","832/832 [==============================] - ETA: 0s - loss: 7097.5259\n","Epoch 00004: val_loss improved from 8203.83691 to 5687.47852, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen/assets\n","832/832 [==============================] - 721s 866ms/step - loss: 7097.5259 - val_loss: 5687.4785\n","Epoch 5/20\n","832/832 [==============================] - ETA: 0s - loss: 5966.9302\n","Epoch 00005: val_loss did not improve from 5687.47852\n","832/832 [==============================] - 634s 762ms/step - loss: 5966.9302 - val_loss: 5786.8540\n","Epoch 6/20\n","832/832 [==============================] - ETA: 0s - loss: 5575.7021\n","Epoch 00006: val_loss did not improve from 5687.47852\n","832/832 [==============================] - 618s 743ms/step - loss: 5575.7021 - val_loss: 6865.6528\n","Epoch 7/20\n","832/832 [==============================] - ETA: 0s - loss: 5897.5566\n","Epoch 00007: val_loss improved from 5687.47852 to 4842.85254, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen/assets\n","832/832 [==============================] - 707s 850ms/step - loss: 5897.5566 - val_loss: 4842.8525\n","Epoch 8/20\n","832/832 [==============================] - ETA: 0s - loss: 5545.6504\n","Epoch 00008: val_loss did not improve from 4842.85254\n","832/832 [==============================] - 627s 754ms/step - loss: 5545.6504 - val_loss: 13921.9639\n","Epoch 9/20\n","832/832 [==============================] - ETA: 0s - loss: 4723.4985\n","Epoch 00009: val_loss improved from 4842.85254 to 3443.08398, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen/assets\n","832/832 [==============================] - 720s 866ms/step - loss: 4723.4985 - val_loss: 3443.0840\n","Epoch 10/20\n","832/832 [==============================] - ETA: 0s - loss: 4806.4575\n","Epoch 00010: val_loss improved from 3443.08398 to 3304.36328, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_1959_AutoDrive_frozen/assets\n","832/832 [==============================] - 733s 881ms/step - loss: 4806.4575 - val_loss: 3304.3633\n","Epoch 11/20\n","832/832 [==============================] - ETA: 0s - loss: 6041.7734\n","Epoch 00011: val_loss did not improve from 3304.36328\n","832/832 [==============================] - 644s 774ms/step - loss: 6041.7734 - val_loss: 8459.9434\n","Epoch 12/20\n","832/832 [==============================] - ETA: 0s - loss: 6356.8086\n","Epoch 00012: val_loss did not improve from 3304.36328\n","832/832 [==============================] - 636s 764ms/step - loss: 6356.8086 - val_loss: 4553.4653\n","Epoch 13/20\n","832/832 [==============================] - ETA: 0s - loss: 5061.8813\n","Epoch 00013: val_loss did not improve from 3304.36328\n","832/832 [==============================] - 639s 768ms/step - loss: 5061.8813 - val_loss: 4568.7109\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uWncwLvD4G5s","colab_type":"code","colab":{}},"source":["keras.models.load_model(f'{os.path.join(mount_path,model_path)}_AutoDrive_frozen')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5oR7eozP668k","colab_type":"code","colab":{}},"source":["# unfreeze the base model which is inside the first timedistributed layer\n","model.layers[0].trainable=True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MXqkHZgR664S","colab_type":"code","colab":{}},"source":["init_lr=1e-4\n","optimizer = keras.optimizers.Nadam(lr=init_lr)\n","loss_function = keras.losses.MeanSquaredError()\n","\n","model.compile(loss=loss_function, optimizer=optimizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2NMIQSI66z6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"ok","timestamp":1599201548397,"user_tz":240,"elapsed":15140337,"user":{"displayName":"Ben Isaacoff","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj3nUiOdsgkozK1xAE5MY_jUwIPqARauxrhKcoSXg=s64","userId":"05140603897186853519"}},"outputId":"42503329-b82d-4496-c3f2-6adba4972a57"},"source":["datestr=datetime.datetime.now(pytz.timezone('US/Eastern')).strftime(\"%y%m%d_%H%M\")\n","checkpoint_filepath=f'{os.path.join(mount_path,model_path)}{datestr}_AutoDrive_unfrozen'\n","model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n","    filepath = checkpoint_filepath,\n","    save_weights_only = False,\n","    monitor = 'val_loss',\n","    mode = 'min',\n","    save_best_only = True,\n","    verbose = 1)\n","\n","batch_size = 8\n","max_epochs = 20\n","\n","train_steps=train_df.shape[0]//batch_size\n","val_steps=val_df.shape[0]//batch_size\n","\n","# train it!\n","history = model.fit(imageseq_generator(train_df,batch_size), epochs = max_epochs,\n","                    validation_data = imageseq_generator(val_df,batch_size),\n","                    steps_per_epoch = train_steps, validation_steps = val_steps,\n","                    callbacks = [early_stopping_cb, model_checkpoint_cb])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","6661/6661 [==============================] - ETA: 0s - loss: 50057.4648\n","Epoch 00001: val_loss improved from inf to 45496.95312, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_2226_AutoDrive_unfrozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_2226_AutoDrive_unfrozen/assets\n","6661/6661 [==============================] - 3062s 460ms/step - loss: 50057.4648 - val_loss: 45496.9531\n","Epoch 2/20\n","6661/6661 [==============================] - ETA: 0s - loss: 47290.0664\n","Epoch 00002: val_loss improved from 45496.95312 to 44915.18750, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_2226_AutoDrive_unfrozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_2226_AutoDrive_unfrozen/assets\n","6661/6661 [==============================] - 3055s 459ms/step - loss: 47290.0664 - val_loss: 44915.1875\n","Epoch 3/20\n","6661/6661 [==============================] - ETA: 0s - loss: 46013.5117\n","Epoch 00003: val_loss improved from 44915.18750 to 44828.23047, saving model to /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_2226_AutoDrive_unfrozen\n","INFO:tensorflow:Assets written to: /content/gdrive/My Drive/AI For Good - AI Blitz 3/AutoDrive/Models/200903_2226_AutoDrive_unfrozen/assets\n","6661/6661 [==============================] - 3052s 458ms/step - loss: 46013.5117 - val_loss: 44828.2305\n","Epoch 4/20\n","6661/6661 [==============================] - ETA: 0s - loss: 45969.9297\n","Epoch 00004: val_loss did not improve from 44828.23047\n","6661/6661 [==============================] - 2957s 444ms/step - loss: 45969.9297 - val_loss: 44863.5781\n","Epoch 5/20\n","6661/6661 [==============================] - ETA: 0s - loss: 45917.9258\n","Epoch 00005: val_loss did not improve from 44828.23047\n","6661/6661 [==============================] - 2958s 444ms/step - loss: 45917.9258 - val_loss: 44957.5195\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O767YW3E66wu","colab_type":"code","colab":{}},"source":["# datestr=datetime.datetime.now(pytz.timezone('US/Eastern')).strftime(\"%y%m%d_%H%M\")\n","# model.save(f'{os.path.join(mount_path,model_path)}{datestr}_AutoDrive_unfrozen')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eog8kD-IoG6G","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}